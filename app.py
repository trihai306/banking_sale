import gradio as gr
import torch
import whisper
import edge_tts
import asyncio
import io
import numpy as np
from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, TextIteratorStreamer
from threading import Thread
from queue import Queue
import tempfile
import os


# Load model v√† tokenizer
MODEL_NAME = "hainguyen306201/bank-model"

# Kh·ªüi t·∫°o model v√† tokenizer m·ªôt l·∫ßn khi app kh·ªüi ƒë·ªông
model = None
tokenizer = None
whisper_model = None

def load_models():
    """Load t·∫•t c·∫£ models"""
    global model, tokenizer, whisper_model
    try:
        print("ƒêang t·∫£i model bank-model...")
        model = AutoModelForCausalLM.from_pretrained(
            MODEL_NAME,
            low_cpu_mem_usage=True,
            torch_dtype=torch.bfloat16,
            device_map="auto"
        )
        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)
        print("Model ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")
        
        # Load Whisper model cho STT
        print("ƒêang t·∫£i Whisper model cho STT...")
        whisper_model = whisper.load_model("base")
        print("Whisper model ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")
        return True
    except Exception as e:
        print(f"L·ªói khi t·∫£i model: {e}")
        return False

# Load models
load_models()

# System message m·∫∑c ƒë·ªãnh
DEFAULT_SYSTEM_MESSAGE = "You are a helpful banking and finance assistant specialized in providing financial advice and banking services information. Respond in Vietnamese when the user speaks Vietnamese."


def speech_to_text(audio):
    """
    STT: Chuy·ªÉn ƒë·ªïi audio th√†nh text
    """
    if audio is None:
        return None
    
    if whisper_model is None:
        return "L·ªói: Whisper model ch∆∞a ƒë∆∞·ª£c t·∫£i. Vui l√≤ng ƒë·ª£i..."
    
    try:
        # Whisper x·ª≠ l√Ω audio file
        result = whisper_model.transcribe(audio, language="vi")
        text = result["text"].strip()
        return text
    except Exception as e:
        print(f"L·ªói STT: {e}")
        return None


def generate_response_stream(
    message,
    history: list,
    system_message,
    max_tokens,
    temperature,
    top_p,
):
    """
    LLM: T·∫°o response t·ª´ LLM v·ªõi streaming
    """
    if model is None or tokenizer is None:
        yield "L·ªói: Model ch∆∞a ƒë∆∞·ª£c t·∫£i. Vui l√≤ng ƒë·ª£i ho·∫∑c refresh trang..."
        return
    
    # Chu·∫©n b·ªã messages
    messages = []
    if system_message:
        messages.append({"role": "system", "content": system_message})
    else:
        messages.append({"role": "system", "content": DEFAULT_SYSTEM_MESSAGE})
    
    # Th√™m l·ªãch s·ª≠ chat
    messages.extend(history)
    
    # Th√™m message hi·ªán t·∫°i
    messages.append({"role": "user", "content": message})
    
    # √Åp d·ª•ng chat template
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True
    )
    
    # Tokenize input
    model_inputs = tokenizer([text], return_tensors="pt").to(model.device)
    
    # C·∫•u h√¨nh generation
    generation_config = GenerationConfig(
        max_new_tokens=min(max_tokens, 16384),
        do_sample=True,
        temperature=temperature,
        top_p=top_p,
        top_k=20,
    )
    
    # T·∫°o streamer ƒë·ªÉ stream response theo th·ªùi gian th·ª±c
    streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)
    
    # C·∫•u h√¨nh generation v·ªõi streamer
    generation_kwargs = {
        **model_inputs,
        "generation_config": generation_config,
        "pad_token_id": tokenizer.eos_token_id,
        "streamer": streamer,
    }
    
    # Ch·∫°y generation trong thread ri√™ng
    thread = Thread(target=model.generate, kwargs=generation_kwargs)
    thread.start()
    
    # Stream response
    response_text = ""
    for new_text in streamer:
        response_text += new_text
        yield response_text


async def text_to_speech_async(text, voice="vi-VN-HoaiMyNeural"):
    """
    TTS: Chuy·ªÉn ƒë·ªïi text th√†nh audio (async)
    """
    try:
        # S·ª≠ d·ª•ng edge-tts ƒë·ªÉ t·∫°o audio
        communicate = edge_tts.Communicate(text, voice)
        audio_data = b""
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                audio_data += chunk["data"]
        
        # T·∫°o file audio t·∫°m
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
            tmp_file.write(audio_data)
            return tmp_file.name
    except Exception as e:
        print(f"L·ªói TTS: {e}")
        return None


def text_to_speech(text):
    """
    TTS wrapper (sync)
    """
    if not text:
        return None
    try:
        return asyncio.run(text_to_speech_async(text))
    except Exception as e:
        print(f"L·ªói TTS: {e}")
        return None


def process_voice_input(
    audio,
    history: list,
    system_message,
    max_tokens,
    temperature,
    top_p,
):
    """
    X·ª≠ l√Ω voice input: STT ‚Üí LLM ‚Üí TTS
    """
    # STT: Chuy·ªÉn audio th√†nh text
    user_text = speech_to_text(audio)
    if not user_text:
        return history, None, "Kh√¥ng th·ªÉ nh·∫≠n di·ªán gi·ªçng n√≥i. Vui l√≤ng th·ª≠ l·∫°i."
    
    # Th√™m user message v√†o history
    history.append({"role": "user", "content": user_text})
    
    # LLM: T·∫°o response v·ªõi streaming
    response_text = ""
    for partial_text in generate_response_stream(
        user_text, history[:-1], system_message, max_tokens, temperature, top_p
    ):
        response_text = partial_text
    
    # Th√™m assistant response v√†o history
    history.append({"role": "assistant", "content": response_text})
    
    # TTS: Chuy·ªÉn response th√†nh audio
    audio_output = text_to_speech(response_text)
    
    return history, audio_output, response_text


def process_text_input(
    message,
    history: list,
    system_message,
    max_tokens,
    temperature,
    top_p,
):
    """
    X·ª≠ l√Ω text input: LLM ‚Üí TTS (optional)
    """
    if not message:
        return history, None, ""
    
    # Th√™m user message v√†o history
    history.append({"role": "user", "content": message})
    
    # LLM: T·∫°o response v·ªõi streaming
    response_text = ""
    for partial_text in generate_response_stream(
        message, history[:-1], system_message, max_tokens, temperature, top_p
    ):
        response_text = partial_text
    
    # Th√™m assistant response v√†o history
    history.append({"role": "assistant", "content": response_text})
    
    return history, response_text


def chat_with_voice(
    audio,
    message,
    history: list,
    system_message,
    max_tokens,
    temperature,
    top_p,
    enable_tts,
):
    """
    H√†m ch√≠nh x·ª≠ l√Ω c·∫£ voice v√† text input
    """
    if audio is not None:
        # X·ª≠ l√Ω voice input
        history, audio_output, response_text = process_voice_input(
            audio, history, system_message, max_tokens, temperature, top_p
        )
        return history, response_text, audio_output if enable_tts else None
    elif message:
        # X·ª≠ l√Ω text input
        history, response_text = process_text_input(
            message, history, system_message, max_tokens, temperature, top_p
        )
        audio_output = text_to_speech(response_text) if enable_tts else None
        return history, response_text, audio_output
    else:
        return history, "", None


def stream_chat_response(
    message,
    history: list,
    system_message,
    max_tokens,
    temperature,
    top_p,
):
    """
    Stream response cho text chat
    """
    if not message:
        return history, ""
    
    # Th√™m user message v√†o history
    history.append({"role": "user", "content": message})
    
    # Stream response t·ª´ LLM
    response_text = ""
    for partial_text in generate_response_stream(
        message, history[:-1], system_message, max_tokens, temperature, top_p
    ):
        response_text = partial_text
        # C·∫≠p nh·∫≠t history v·ªõi partial response
        temp_history = history.copy()
        temp_history.append({"role": "assistant", "content": response_text})
        yield temp_history, response_text
    
    # C·∫≠p nh·∫≠t history cu·ªëi c√πng
    history.append({"role": "assistant", "content": response_text})


# T·∫°o Gradio interface
with gr.Blocks(title="Bank Model Voice Chat", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # üè¶ Bank Model Voice Chat
    
    ·ª®ng d·ª•ng t∆∞ v·∫•n ng√¢n h√†ng v√† t√†i ch√≠nh v·ªõi h·ªó tr·ª£ gi·ªçng n√≥i.
    
    **Ki·∫øn tr√∫c**: STT (Speech-to-Text) ‚Üí LLM ‚Üí TTS (Text-to-Speech)
    
    - üé§ **Voice Input**: N√≥i v√†o microphone ƒë·ªÉ ƒë·∫∑t c√¢u h·ªèi
    - üí¨ **Text Input**: G√µ c√¢u h·ªèi b·∫±ng vƒÉn b·∫£n
    - üîä **Voice Output**: Nghe c√¢u tr·∫£ l·ªùi b·∫±ng gi·ªçng n√≥i (t√πy ch·ªçn)
    """)
    
    with gr.Row():
        with gr.Column(scale=2):
            chatbot = gr.Chatbot(
                label="Chat",
                height=500,
                show_copy_button=True,
            )
            
            with gr.Row():
                audio_input = gr.Audio(
                    sources=["microphone"],
                    type="filepath",
                    label="üé§ N√≥i v√†o ƒë√¢y",
                    show_label=True,
                )
                text_input = gr.Textbox(
                    label="üí¨ Ho·∫∑c g√µ c√¢u h·ªèi",
                    placeholder="Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n...",
                    lines=2,
                )
            
            with gr.Row():
                submit_voice_btn = gr.Button("üé§ G·ª≠i (Voice)", variant="primary")
                submit_text_btn = gr.Button("üí¨ G·ª≠i (Text)", variant="primary")
                clear_btn = gr.Button("üóëÔ∏è X√≥a l·ªãch s·ª≠", variant="secondary")
        
        with gr.Column(scale=1):
            gr.Markdown("### ‚öôÔ∏è C√†i ƒë·∫∑t")
            
            system_msg = gr.Textbox(
                value=DEFAULT_SYSTEM_MESSAGE,
                label="System Message",
                lines=3,
            )
            
            max_tokens = gr.Slider(
                minimum=1,
                maximum=16384,
                value=2048,
                step=1,
                label="Max Tokens",
            )
            
            temperature = gr.Slider(
                minimum=0.1,
                maximum=2.0,
                value=0.7,
                step=0.1,
                label="Temperature",
            )
            
            top_p = gr.Slider(
                minimum=0.1,
                maximum=1.0,
                value=0.8,
                step=0.05,
                label="Top-p",
            )
            
            enable_tts = gr.Checkbox(
                value=True,
                label="üîä B·∫≠t TTS (Text-to-Speech)",
            )
            
            audio_output = gr.Audio(
                label="üîä C√¢u tr·∫£ l·ªùi b·∫±ng gi·ªçng n√≥i",
                type="filepath",
                autoplay=True,
            )
            
            with gr.Accordion("‚ÑπÔ∏è Th√¥ng tin", open=False):
                gr.Markdown("""
                **Model**: hainguyen306201/bank-model
                - Fine-tuned t·ª´ Qwen3-4B-Instruct-2507
                - Chuy√™n v·ªÅ t∆∞ v·∫•n ng√¢n h√†ng v√† t√†i ch√≠nh
                - H·ªó tr·ª£ ƒëa ng√¥n ng·ªØ (∆∞u ti√™n ti·∫øng Vi·ªát)
                
                **STT**: OpenAI Whisper (base)
                **TTS**: Edge-TTS (vi-VN-HoaiMyNeural)
                """)
    
    # State ƒë·ªÉ l∆∞u l·ªãch s·ª≠ chat
    history_state = gr.State(value=[])
    
    # Event handlers
    def submit_voice(audio, history, system_msg, max_tok, temp, top_p_val, tts_enabled):
        if audio is None:
            return history, "", None, history
        new_history, response_text, audio_out = chat_with_voice(
            audio, None, history, system_msg, max_tok, temp, top_p_val, tts_enabled
        )
        return new_history, response_text, audio_out, new_history
    
    def submit_text_stream(message, history, system_msg, max_tok, temp, top_p_val, tts_enabled):
        if not message:
            return history, "", None, history
        
        # Th√™m user message v√†o history
        history.append({"role": "user", "content": message})
        
        # Stream response t·ª´ LLM
        response_text = ""
        for partial_text in generate_response_stream(
            message, history[:-1], system_msg, max_tok, temp, top_p_val
        ):
            response_text = partial_text
            # C·∫≠p nh·∫≠t history v·ªõi partial response
            temp_history = history.copy()
            temp_history.append({"role": "assistant", "content": response_text})
            yield temp_history, "", None, temp_history
        
        # C·∫≠p nh·∫≠t history cu·ªëi c√πng
        history.append({"role": "assistant", "content": response_text})
        
        # T·∫°o audio n·∫øu TTS ƒë∆∞·ª£c b·∫≠t
        audio_out = text_to_speech(response_text) if tts_enabled else None
        yield history, "", audio_out, history
    
    def clear_chat():
        return [], "", None, []
    
    # Bind events
    submit_voice_btn.click(
        fn=submit_voice,
        inputs=[audio_input, history_state, system_msg, max_tokens, temperature, top_p, enable_tts],
        outputs=[chatbot, text_input, audio_output, history_state],
    ).then(
        fn=lambda: None,
        outputs=[audio_input],
    )
    
    submit_text_btn.click(
        fn=submit_text_stream,
        inputs=[text_input, history_state, system_msg, max_tokens, temperature, top_p, enable_tts],
        outputs=[chatbot, text_input, audio_output, history_state],
    ).then(
        fn=lambda: "",
        outputs=[text_input],
    )
    
    text_input.submit(
        fn=submit_text_stream,
        inputs=[text_input, history_state, system_msg, max_tokens, temperature, top_p, enable_tts],
        outputs=[chatbot, text_input, audio_output, history_state],
    ).then(
        fn=lambda: "",
        outputs=[text_input],
    )
    
    clear_btn.click(
        fn=clear_chat,
        outputs=[chatbot, text_input, audio_output, history_state],
    )


if __name__ == "__main__":
    # Ki·ªÉm tra models ƒë√£ ƒë∆∞·ª£c load ch∆∞a
    if model is None or tokenizer is None or whisper_model is None:
        print("‚ö†Ô∏è C·∫£nh b√°o: M·ªôt s·ªë models ch∆∞a ƒë∆∞·ª£c t·∫£i. App v·∫´n s·∫Ω ch·∫°y nh∆∞ng c√≥ th·ªÉ g·∫∑p l·ªói.")
    
    # Hugging Face Spaces s·∫Ω t·ª± ƒë·ªông x·ª≠ l√Ω server configuration
    demo.launch()
