{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clone Qwen3-4B-Instruct-2507 v√† Upload l√™n Hugging Face\n",
        "\n",
        "Notebook n√†y s·∫Ω:\n",
        "1. C√†i ƒë·∫∑t Hugging Face CLI\n",
        "2. Clone model Qwen3-4B-Instruct-2507\n",
        "3. T·∫°o model m·ªõi c·ªßa b·∫°n ƒë·ªÉ training\n",
        "4. Upload model l√™n Hugging Face repository: `hainguyen306201/bank-model`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
        "%pip install -q transformers accelerate torch huggingface_hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# C√†i ƒë·∫∑t Hugging Face CLI\n",
        "!curl -LsSf https://hf.co/cli/install.sh | bash\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Th√™m Hugging Face CLI v√†o PATH (cho Colab)\n",
        "import os\n",
        "os.environ['PATH'] = f\"{os.environ['HOME']}/.local/bin:{os.environ['PATH']}\"\n",
        "\n",
        "# Ki·ªÉm tra c√†i ƒë·∫∑t\n",
        "!hf --version\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B∆∞·ªõc 1: L·∫•y Hugging Face Token t·ª´ Colab Secrets\n",
        "\n",
        "Token ƒë√£ ƒë∆∞·ª£c l∆∞u trong Colab Secrets v·ªõi key `hf_token`. \n",
        "N·∫øu ch∆∞a c√≥, b·∫°n c√≥ th·ªÉ th√™m b·∫±ng c√°ch: üîë (key icon) ‚Üí Secrets ‚Üí Add new secret ‚Üí Key: `hf_token`, Value: [token c·ªßa b·∫°n]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# L·∫•y Hugging Face token t·ª´ Colab Secrets\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# L·∫•y token t·ª´ Secrets (key: hf_token)\n",
        "hf_token = userdata.get('hf_token')\n",
        "\n",
        "# Thi·∫øt l·∫≠p token v√†o environment variable ƒë·ªÉ c√°c l·ªánh hf t·ª± ƒë·ªông s·ª≠ d·ª•ng\n",
        "os.environ['HF_TOKEN'] = hf_token\n",
        "os.environ['HUGGING_FACE_HUB_TOKEN'] = hf_token\n",
        "\n",
        "# L∆∞u token v√†o file ƒë·ªÉ hf CLI c√≥ th·ªÉ s·ª≠ d·ª•ng\n",
        "# Hugging Face CLI l∆∞u token ·ªü ~/.huggingface/token\n",
        "hf_home = os.path.expanduser(\"~/.huggingface\")\n",
        "os.makedirs(hf_home, exist_ok=True)\n",
        "token_file = os.path.join(hf_home, \"token\")\n",
        "with open(token_file, \"w\") as f:\n",
        "    f.write(hf_token)\n",
        "\n",
        "print(\"‚úÖ ƒê√£ thi·∫øt l·∫≠p Hugging Face token t·ª´ Colab Secrets!\")\n",
        "print(\"Token ƒë√£ ƒë∆∞·ª£c l∆∞u v√† s·∫Ω ƒë∆∞·ª£c s·ª≠ d·ª•ng t·ª± ƒë·ªông cho c√°c l·ªánh hf\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B∆∞·ªõc 2: Clone model Qwen3-4B-Instruct-2507\n",
        "\n",
        "T·∫£i model v·ªÅ local ƒë·ªÉ c√≥ th·ªÉ ch·ªânh s·ª≠a v√† training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T·∫°o th∆∞ m·ª•c ƒë·ªÉ l∆∞u model\n",
        "import os\n",
        "model_dir = \"./bank-model\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "print(f\"ƒê√£ t·∫°o th∆∞ m·ª•c: {model_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone model t·ª´ Hugging Face\n",
        "source_model = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
        "target_dir = \"./bank-model\"\n",
        "\n",
        "print(f\"ƒêang clone model {source_model}...\")\n",
        "!hf download {source_model} --local-dir {target_dir} --local-dir-use-symlinks False\n",
        "\n",
        "print(\"\\n‚úÖ ƒê√£ clone model th√†nh c√¥ng!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ki·ªÉm tra c√°c file ƒë√£ ƒë∆∞·ª£c t·∫£i v·ªÅ\n",
        "import os\n",
        "files = os.listdir(target_dir)\n",
        "print(\"C√°c file trong th∆∞ m·ª•c model:\")\n",
        "for file in sorted(files):\n",
        "    file_path = os.path.join(target_dir, file)\n",
        "    size = os.path.getsize(file_path) / (1024 * 1024)  # MB\n",
        "    print(f\"  - {file}: {size:.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B∆∞·ªõc 3: T·∫°o README.md cho model m·ªõi (t√πy ch·ªçn)\n",
        "\n",
        "B·∫°n c√≥ th·ªÉ t√πy ch·ªânh README.md cho model c·ªßa m√¨nh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T·∫°o README.md cho model m·ªõi\n",
        "readme_content = \"\"\"---\n",
        "license: apache-2.0\n",
        "base_model: Qwen/Qwen3-4B-Instruct-2507\n",
        "tags:\n",
        "- banking\n",
        "- finance\n",
        "- vietnamese\n",
        "- qwen3\n",
        "---\n",
        "\n",
        "# Bank Model\n",
        "\n",
        "Model n√†y ƒë∆∞·ª£c fine-tuned t·ª´ Qwen3-4B-Instruct-2507 cho c√°c t√°c v·ª• li√™n quan ƒë·∫øn ng√¢n h√†ng v√† t√†i ch√≠nh.\n",
        "\n",
        "## Model Details\n",
        "\n",
        "- **Base Model**: Qwen/Qwen3-4B-Instruct-2507\n",
        "- **Parameters**: 4.0B\n",
        "- **Context Length**: 262,144 tokens\n",
        "\n",
        "## Usage\n",
        "\n",
        "```python\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"hainguyen306201/bank-model\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# S·ª≠ d·ª•ng model...\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "with open(os.path.join(target_dir, \"README.md\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(readme_content)\n",
        "\n",
        "print(\"‚úÖ ƒê√£ t·∫°o README.md\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B∆∞·ªõc 4: Upload model l√™n Hugging Face\n",
        "\n",
        "Upload model l√™n repository `hainguyen306201/bank-model`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload model l√™n Hugging Face\n",
        "repo_id = \"hainguyen306201/bank-model\"\n",
        "upload_dir = \"./bank-model\"\n",
        "\n",
        "print(f\"ƒêang upload model l√™n {repo_id}...\")\n",
        "print(\"L∆∞u √Ω: Repository s·∫Ω ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông n·∫øu ch∆∞a t·ªìn t·∫°i\")\n",
        "\n",
        "!cd {upload_dir} && hf upload {repo_id} . --repo-type model\n",
        "\n",
        "print(\"\\n‚úÖ ƒê√£ upload model th√†nh c√¥ng!\")\n",
        "print(f\"B·∫°n c√≥ th·ªÉ truy c·∫≠p model t·∫°i: https://huggingface.co/{repo_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B∆∞·ªõc 5: Ki·ªÉm tra model ƒë√£ ƒë∆∞·ª£c upload (t√πy ch·ªçn)\n",
        "\n",
        "Ki·ªÉm tra xem model ƒë√£ c√≥ tr√™n Hugging Face ch∆∞a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ki·ªÉm tra th√¥ng tin repository\n",
        "repo_id = \"hainguyen306201/bank-model\"\n",
        "!hf repo info {repo_id}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ho√†n th√†nh! üéâ\n",
        "\n",
        "Model ƒë√£ ƒë∆∞·ª£c clone v√† upload th√†nh c√¥ng. B√¢y gi·ªù b·∫°n c√≥ th·ªÉ:\n",
        "- Fine-tune model n√†y v·ªõi d·ªØ li·ªáu c·ªßa b·∫°n\n",
        "- S·ª≠ d·ª•ng model trong c√°c ·ª©ng d·ª•ng c·ªßa b·∫°n\n",
        "- Chia s·∫ª model v·ªõi c·ªông ƒë·ªìng\n",
        "\n",
        "### ƒê·ªÉ training model, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng:\n",
        "- **PEFT/LoRA**: ƒê·ªÉ fine-tune hi·ªáu qu·∫£ v·ªõi √≠t t√†i nguy√™n\n",
        "- **Transformers Trainer**: ƒê·ªÉ training full model\n",
        "- **Unsloth**: ƒê·ªÉ training nhanh h∆°n v·ªõi b·ªô nh·ªõ t·ªëi ∆∞u\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
